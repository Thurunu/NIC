import numpy as np
import pandas as pd
import random
import matplotlib.pyplot
%matplotlib inline


from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler


cancer = load_breast_cancer()
df = pd.DataFrame(
    cancer['data'],
    columns = cancer['feature_names'])
label = cancer['target']


df


len(df)


X_train, X_test, Y_train, Y_test = train_test_split(df, 
                                                    label, 
                                                    test_size=0.30,
                                                    random_state=101 )


X_train


logmodel = LogisticRegression(solver='liblinear', max_iter=1000)
logmodel.fit(X_train, Y_train)
predictions = logmodel.predict(X_test)


accuracy = str(accuracy_score(Y_test, predictions))
accuracy


# we take n_feat = 30 cause dataset has 30 columns so we can clearly mapped columns
n_feat=30 #gene count for each chromosome
chromosome = np.ones(n_feat, dtype=bool) # Initialize chromosome

print("Chromosome Before Randomness: \n" , chromosome)


chromosome[:int(0.3*n_feat)] = False # 3% of the chromosome make False. This is done to introduce randomness
print("Chromosome After Randomness: \n", chromosome)


np.random.shuffle(chromosome) # now we shuffle the False 
print("Chromosome after random shuffeling: \n", chromosome)


population = []
population.append(chromosome) # add chromosome to the population as an individual
print("Population: \n", population)


# now we shuffle chromosome and apply randomness to it, so to training we don't use entire 30 features from the dataset,
# we remove corresponding False columns from the dataset, which columns corresponding with True those are take for training.
# so iloc() from this we can remove corresponding False columns from the dataset
x = X_train.iloc[:, chromosome]
x





chromo, score = generations(size=20, n_feat=30, n_parents=8, mutation_rate=0.10, n_gen=20, X_train=X_train, X_test=X_test,Y_train=Y_train,Y_test=Y_test)
max_score = max(score)
max_index = score.index(max_score)
logmodel.fit(X_train.iloc[:,chromo[max_index]], Y_train)  
predictions = logmodel.predict(X_test.iloc[:, chromo[max_index]])
accuracy = str(accuracy_score(Y_test, predictions))



print ("Accuracy score after genetic algorithm is: ", accuracy)


score.index(max_score)


score


chromo


#size = population size / no of individuals
#n_feat = how many genes match with the dataset features
#n_parents = how many parents for mating
#mutation rate = this means we flip a gene in 0.1 rate
#n-gen = how many generations need to pass
def generations(size, n_feat, n_parents, mutation_rate, n_gen, X_train, X_test, Y_train, Y_test):
    best_chromo = []
    best_score = []
    all_scores = {}
    population_nextgen = initilization_of_population(size, n_feat) 
    for i in range(n_gen):
        scores, pop_after_fit = fitness_score(population_nextgen)
        all_scores[i] = scores
        pop_after_selection = selection(pop_after_fit, n_parents) # top 8 individuals willbe selected according to their fitness scores
        # print("Length after selection: ", len(pop_after_selection))
        pop_after_cross = crossover(pop_after_selection) # now we get a population of new chromosomes
        # print("Length after crossover: ", len(pop_after_cross))
        population_nextgen = mutation(pop_after_cross, mutation_rate)
        best_chromo.append(pop_after_fit[0]) # get the best chromosome which get the highest fitness score, from each iteration
        best_score.append(scores[0]) # and the score get by the particular chromosome
    return best_chromo, best_score
        


def initilization_of_population(size, n_feat):
    population = []
    for i in range(size):
        chromosome = np.ones(n_feat, dtype=bool) # all 30 genes make True
        chromosome[:int(0.3*n_feat)] = False # make 3% of genes False
        np.random.shuffle(chromosome) # shuffle False with Trues to make randomness 
        population.append(chromosome)
    return population # individual population is ready


def fitness_score(population):
    scores = []
    for chromosome in population:
        logmodel.fit(X_train.iloc[:, chromosome], Y_train) # iloc() used to extract corresponding True features from the dataset
        predictions = logmodel.predict(X_test.iloc[:, chromosome]) # verify the training accuracy for selected features
        scores.append(accuracy_score(Y_test, predictions)) # store the accuracy score for each individual
    scores, population = np.array(scores), np.array(population) # store predicition accuacy for different chromosome combinations of chromosomes
    inds = np.argsort(scores) # from here we sort the scores from low to high; from that we can find which individual has the highest fitness score
    return list(scores[inds][::-1]), list(population[inds,:][::-1]) # we need highest accuracy and the corresponding chromosome that's why we use -1


def selection(pop_after_fit, parents):
    population_nextgen = []
    for i in range(parents):
        population_nextgen.append(pop_after_fit[i]) # first 8 individual will take as parents
    return population_nextgen


def crossover(pop_after_selection):
    population_nextgen = pop_after_selection
    for i in range(len(pop_after_selection)):
        child = pop_after_selection[i] # get parents for cross over
        child_represent = child
        # print("Chromosome: ", child_represent.astype(int))
        child_before_crossover_represent = child[3:7] # extract only 4 genes from the parent
        # print("Before Crossover: ", child_before_crossover_represent.astype(int))
        # print("Cross over calculation: ", pop_after_selection[(i+1)%len(pop_after_selection)].astype(int))
        child[3:7] = pop_after_selection[(i+1)%len(pop_after_selection)][3:7]
        child_after_crossover_represent = child[3:7].astype(int)
        # print("After Crossover:", child_after_crossover_represent)
        population_nextgen.append(child)
    return population_nextgen


def mutation(pop_after_cross, mutation_rate):
    population_nextgen = []

    for i in range(0, len(pop_after_cross)):
        chromosome = pop_after_cross[i]
        for j in range (len(chromosome)):
            # from this loop we go through each gene in each individual, from the if generate a random number and check is it lower than
            # mutation_rate and we do this for stablish randomness
            if random.random() < mutation_rate:
                # print("Gene before change", chromosome[j])
                chromosome[j] = not chromosome[j]
                # print('After Gene Change: ', chromosome[j])
        population_nextgen.append(chromosome)

    return population_nextgen









